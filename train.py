import torch
from torch.utils.data import DataLoader
import torch.optim as optim
from tqdm import tqdm
import matplotlib.pyplot as plt

from conditional_vae import ConditionalVAE_3D, vae_loss_function
from config import (
    PT_FILE_PATH,
    LOSS_PLOT_PATH,
    EPOCHS,
    BATCH_SIZE,
    BETA_KLD_WEIGHT,
    BIOME_EMBED_DIM,
    BLOCK_EMBED_DIM,
    LEARNING_RATE,
    LATENT_DIM,
)
from dataset import MinecraftChunkDataset


def save_loss_plot(train_losses, recon_losses, kld_losses, filename="loss_curve.png"):
    """
    Salva um gr√°fico das curvas de perda.
    """
    plt.figure(figsize=(10, 6))

    # Plota a perda total
    plt.plot(train_losses, label="Perda Total (Total Loss)", color="blue")

    # Plota as componentes da perda
    plt.plot(
        recon_losses,
        label="Perda de Reconstru√ß√£o (Recon)",
        color="green",
        linestyle="--",
    )
    plt.plot(kld_losses, label="Perda KL (KLD)", color="red", linestyle="--")

    plt.title("Curvas de Perda do Treinamento da VAE")
    plt.xlabel("√âpoca (Epoch)")
    plt.ylabel("Perda (Loss)")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()

    plt.savefig(filename)
    print(f"Gr√°fico de perda salvo em '{filename}'")

    plt.close()
    

if __name__ == "__main__":
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Usando dispositivo: {device}")
    print("Carregando dataset...")
    try:
        dataset = MinecraftChunkDataset(PT_FILE_PATH)

        dataloader = DataLoader(
            dataset,
            batch_size=BATCH_SIZE,
            shuffle=True,
            num_workers=4,
            pin_memory=True,
        )
    except Exception as e:
        print(f"Erro ao carregar o dataset: {e}")
        exit()

    # --- 2. Instanciar Modelo e Otimizador ---
    print("Construindo modelo...")
    model = ConditionalVAE_3D(
        num_classes=dataset.num_unique_blocks,  # N√∫mero de blocos √∫nicos no dataset
        num_biomes=dataset.num_biomes,  # N√∫mero de biomas √∫nicos no dataset
        latent_dim=LATENT_DIM,  # Dimens√£o do espa√ßo latente
        block_embed_dim=BLOCK_EMBED_DIM,  # Dimens√£o do embedding dos blocos
        biome_embed_dim=BIOME_EMBED_DIM,  # Dimens√£o do embedding dos biomas
    ).to(device)

    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)  # Otimizador Adam

    history_total_loss = []  # Hist√≥rico da perda total
    history_recon_loss = []  # Hist√≥rico da perda de reconstru√ß√£o
    history_kld_loss = []  # Hist√≥rico da perda KL

    print(f"Iniciando treinamento por {EPOCHS} √©pocas...")
    print("-" * 30)

    best_loss = float("inf")  # Come√ßa com infinito para qualquer loss ser menor

    for epoch in range(EPOCHS):
        model.train()  # Define o modelo em modo de treinamento

        epoch_loss_total = 0.0
        epoch_loss_recon = 0.0
        epoch_loss_kld = 0.0

        for batch_blocks, batch_biomes in tqdm(
            dataloader, desc=f"√âpoca {epoch + 1}/{EPOCHS}"
        ):
            blocks = batch_blocks.to(device)  # Move os blocos para o dispositivo
            biomes = batch_biomes.to(device)  # Move os biomas para o dispositivo

            # Passa os dados pelo modelo para obter reconstru√ß√£o e par√¢metros latentes
            reconstructed_logits, mu, logvar = model(blocks, biomes)

            # Calcula a perda total, de reconstru√ß√£o e KL
            total_loss, recon_loss, kld_loss = vae_loss_function(
                reconstructed_logits, blocks, mu, logvar, beta=BETA_KLD_WEIGHT
            )

            optimizer.zero_grad()  # Zera os gradientes acumulados
            total_loss.backward()  # Calcula os gradientes via backpropagation

            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Clipping de gradiente

            optimizer.step()  # Atualiza os pesos do modelo

            # Acumula as perdas para c√°lculo da m√©dia
            epoch_loss_total += total_loss.item()
            epoch_loss_recon += recon_loss.item()
            epoch_loss_kld += kld_loss.item()

        # Calcula as perdas m√©dias por √©poca
        avg_loss_total = epoch_loss_total / len(dataloader)
        avg_loss_recon = epoch_loss_recon / len(dataloader)
        avg_loss_kld = epoch_loss_kld / len(dataloader)

        history_total_loss.append(avg_loss_total)  # Salva a perda total m√©dia
        history_recon_loss.append(avg_loss_recon)  # Salva a perda de reconstru√ß√£o m√©dia
        history_kld_loss.append(avg_loss_kld)  # Salva a perda KL m√©dia

        print(f"\nFim da √âpoca {epoch + 1}")
        print(f"  Perda Total M√©dia: {avg_loss_total:.4f}")

        # Salva o modelo se a perda total for a melhor at√© agora
        if avg_loss_total < best_loss:
            best_loss = avg_loss_total
            torch.save(model.state_dict(), "models/best_vae_model.pt")
            print(f"üåü NOVO RECORDE! Melhor modelo salvo (Loss: {best_loss:.4f})")
        else:
            print(f"  (N√£o superou o recorde de {best_loss:.4f})")

        # Salva o modelo mais recente ap√≥s cada √©poca
        torch.save(model.state_dict(), "models/latest_vae_model.pt")
        print("-" * 30)

    # Salva o gr√°fico das curvas de perda
    save_loss_plot(
        history_total_loss, history_recon_loss, history_kld_loss, LOSS_PLOT_PATH
    )

    print("Treinamento conclu√≠do!")
